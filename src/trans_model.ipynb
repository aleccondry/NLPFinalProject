{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alecc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AdamWeightDecay, TFAutoModelForCausalLM\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "import utils\n",
    "import os\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alecc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = TFAutoModelForCausalLM.from_pretrained('gpt2')\n",
    "\n",
    "# Constants\n",
    "TLDR = ' TL;DR '\n",
    "MAX_LEN = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"../data/cleaned_data/\"\n",
    "if not os.path.exists(datapath):\n",
    "    utils.clean_data()\n",
    "all_articles_dict = utils.load_article_data(path=datapath)\n",
    "del all_articles_dict['clean_Articles.csv']\n",
    "del all_articles_dict['clean_CNN_Articels_clean.csv']\n",
    "all_articles_df = pd.concat([df for df in all_articles_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format data by: article TL;DR headline\n",
    "num_elements = 1000\n",
    "all_articles = all_articles_df.values.tolist()\n",
    "all_articles = [x[1].strip() + \" TL;DR \" + x[0].strip().replace(' - The New York Times', '') \n",
    "                for x in all_articles \n",
    "                if isinstance(x[0], str) and isinstance(x[1], str)][0:num_elements]\n",
    "\n",
    "def pad_and_truncate_data(dataset):\n",
    "    \"\"\"\n",
    "    Format data to always contain the TL;DR and the entire headline. Truncate the article such that\n",
    "    the whole string becomes MAX_LEN long.\n",
    "    \"\"\"\n",
    "    ARTICLE_LEN = MAX_LEN - len(TLDR)\n",
    "    result = []\n",
    "    for d in dataset:\n",
    "        article, headline = d.split(' TL;DR ')\n",
    "        result.append(article[0:ARTICLE_LEN - len(headline)] + TLDR + headline)\n",
    "    return result\n",
    "\n",
    "all_articles = pad_and_truncate_data(all_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data to files to be loaded into a dataset\n",
    "random.seed(11)\n",
    "random.shuffle(all_articles)\n",
    "TRAIN_SPLIT = 0.9\n",
    "END_IDX = int(len(all_articles) * TRAIN_SPLIT)\n",
    "with open(\"../data/train_data.txt\", \"w\", encoding='utf-8') as txt_file:\n",
    "    for line in all_articles[0:END_IDX]:\n",
    "        txt_file.write(line + \"\\n\") # works with any number of elements in a line\n",
    "with open(\"../data/test_data.txt\", \"w\", encoding='utf-8') as txt_file:\n",
    "    for line in all_articles[END_IDX:]:\n",
    "        txt_file.write(line + \"\\n\") # works with any number of elements in a line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 62.27it/s]\n",
      "Generating train split: 900 examples [00:00, 41874.18 examples/s]\n",
      "Generating validation split: 100 examples [00:00, 5160.51 examples/s]\n"
     ]
    }
   ],
   "source": [
    "datasets = load_dataset(\"text\", data_files={\"train\": '../data/train_data.txt', \"validation\": '../data/test_data.txt'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'The presidency of Donald J. Trump has been noteworthy for its speed. In his first week in office, as the president’s aides won’t tire of reminding us, Mr. Trump has already put in motion plans to do much of what he promised to do while campaigning. But it’s not just the politician who is moving fast. It’s the population, too. In a matter of hours on Saturday, thousands rushed to the nation’s airports, beckoned by tweets. The f TL;DR The Alt-Majority: How Social Networks Empowered Mass Protests Against Trump'}\n",
      "900\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(datasets[\"train\"][10])\n",
    "print(len(datasets['train']))\n",
    "print(len(datasets['validation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizerWrapper:\n",
    "    def __init__(self, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def tokenize_function(self, examples):\n",
    "        return self.tokenizer(examples[\"text\"],\n",
    "                              padding='max_length',\n",
    "                              truncation=True,\n",
    "                              max_length=self.max_len // 4)\n",
    "\n",
    "tokenizer_wrapper = TokenizerWrapper(tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4): 100%|██████████| 900/900 [00:06<00:00, 132.41 examples/s]\n",
      "Map (num_proc=4): 100%|██████████| 100/100 [00:04<00:00, 21.31 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize data\n",
    "tokenized_datasets = datasets.map(\n",
    "    tokenizer_wrapper.tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [5673, 447, 247, 21358, 5984, 5883, 3955, 11, 2688, 5018, 220, 851, 220, 220, 383, 717, 11903, 286, 6669, 447, 247, 1000, 1215, 388, 320, 11, 257, 289, 6548, 1748, 319, 262, 10183, 30140, 286, 10843, 11, 389, 783, 220, 764, 317, 27316, 3443, 4721, 938, 614, 11, 290, 2319, 5085, 389, 11694, 612, 11, 749, 2636, 286, 3288, 5640, 706, 890, 290, 12309, 3160, 13, 1320, 318, 284, 910, 11, 612, 318, 2147, 8584, 546, 428, 1295, 11, 530, 286, 262, 11706, 18573, 284, 10843, 287, 262, 12030, 2688, 5018, 11, 543, 2692, 12000, 422, 8078, 2026, 812, 2084, 13, 564, 250, 1026, 447, 247, 82, 636, 220, 24811, 26, 7707, 2692, 447, 247, 82, 6912, 12, 14993, 364, 16168, 284, 564, 246, 5247, 4403, 447, 247], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "MA’ALE ADUMIM, West Bank  —   The first babies of Ma’ale Adumim, a hilly city on the eastern outskirts of Jerusalem, are now . A cemetery finally opened last year, and 40 residents are buried there, most dead of natural causes after long and peaceful lives. That is to say, there is nothing temporary about this place, one of the closest settlements to Jerusalem in the occupied West Bank, which Israel seized from Jordan 50 years ago. “It’s part  TL;DR Israel’s Hard-Liners Want to ‘Go Big’\n",
      "491\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_datasets[\"train\"][1])\n",
    "print(tokenizer.decode(tokenized_datasets[\"train\"][1][\"input_ids\"]))\n",
    "print(len(tokenizer.decode(tokenized_datasets[\"train\"][1][\"input_ids\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4): 100%|██████████| 900/900 [00:02<00:00, 353.64 examples/s]\n",
      "Map (num_proc=4): 100%|██████████| 100/100 [00:02<00:00, 43.49 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Add labels to tokenized data\n",
    "def add_labels(examples):\n",
    "    examples['labels'] = examples['input_ids'].copy()\n",
    "    return examples\n",
    "\n",
    "lm_datasets = tokenized_datasets.map(\n",
    "    add_labels,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training and validation datasets\n",
    "train_set = model.prepare_tf_dataset(\n",
    "    lm_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=4,\n",
    ")\n",
    "\n",
    "validation_set = model.prepare_tf_dataset(\n",
    "    lm_datasets[\"validation\"],\n",
    "    shuffle=False,\n",
    "    batch_size=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alecc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\optimizers\\legacy\\adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alecc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "225/225 [==============================] - 534s 2s/step - loss: 3.2039 - val_loss: 2.7369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d432702ad0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile and train model\n",
    "optimizer = AdamWeightDecay(lr=2e-5, weight_decay_rate=0.01)\n",
    "model.compile(optimizer=optimizer)\n",
    "model.fit(train_set, \n",
    "          validation_data=validation_set, \n",
    "          epochs=1,  \n",
    "          verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights('../trained_models/gpt2-summarization')\n",
    "model.save_pretrained('../trained_models/gpt2-summarization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at ../trained_models/gpt2-summarization/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForCausalLM.from_pretrained('../trained_models/gpt2-summarization/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not since Lincoln has there been a president as fundamentally shaped  —   in his life, convictions and outlook on the world  —   by reading and writing as Barack Obama. Last Friday, seven days before his departure from the White House, Mr. Obama sat down in the Oval Office and talked about the indispensable role that books have played during his presidency and throughout his life  —   from his peripatetic and sometimes lonely boyhood, when “thes TL;DR    Obama: A Life of Reading and Writing<|endoftext|>\n",
      "Fifty years ago right about now, two unassuming young brothers were standing in front of a CBS studio audience taping the first episode of their new variety show. They were also about to unleash the modern concept of television buzz, in a storm the likes of which the medium had not seen. They were the Smothers Brothers, Tom and Dick, and the    story of their show, “The Smothers Brothers Comedy Hour,” is worth recalling 50 years on as a case study that ma TL;DR  TL;DR Smothers Brothers Comedy Hour, ‘The Smothers Brothers Comedy Hour,’ Is Worth Reading<|endoftext|>\n",
      "A steep drop in gang violence last year drove shootings in New York City to the lowest number in at least a   Police Department data shows, a result of what police officials say has been a focus on gang takedowns and targeted arrests in some of the city’s roughest neighborhoods. The internal police data, obtained by The New York Times, paints a detailed portrait of the motives, locations and circumstances behind murders and shooti TL;DR   Gang Violence Is the New Normal<|endoftext|>\n",
      "Good morning.  (Want to get California Today by email? Here’s the .) Let’s turn it over to Thomas Fuller, our San Francisco bureau chief, for today’s introduction. The titans of Silicon Valley like to claim that they’re inventing technology to change the world, and their philanthropic efforts often mirror those big global goals and dreams, with initiatives to end hunger and fight diseases. But the arts in San Francisco haven’t always fe TL;DR  TL;DR Silicon Valley’s Newest Tech<|endoftext|>\n",
      "KABUL, Afghanistan  —   A double bombing by the Taliban near the Afghan Parliament office compound in Kabul on Tuesday killed dozens of people during the   rush hour, officials said. The assault in the Afghan capital was the deadliest of several   attacks on Tuesday, including an explosion at a government guesthouse in the southern province of Kandahar that wounded the provincial governor and the visiting ambassador of the United Ar TL;DR   Taliban Attack on Afghan Parliament Office in Kabul Kills Dozens<|endoftext|>\n",
      "WASHINGTON  —   Congressional Republicans have a new fear when it comes to their    health care lawsuit against the Obama administration: They might win. The incoming Trump administration could choose to no longer defend the executive branch against the suit, which challenges the administration’s authority to spend billions of dollars on health insurance subsidies for   and   Americans, handing House Republicans a big victory on    issues. Bu TL;DR   Trump’s Health Care Law Is a Big Win for Republicans<|endoftext|>\n",
      "SAN FRANCISCO  —   On Friday morning, Silicon Valley was largely ambivalent about President Trump. The software programmers, marketing experts and chief executives might not have voted for him, but they were hopeful about finding common ground with the new administration. By Saturday night, much of that optimism had yielded to anger and determination. Mr. Trump’s executive order late on Friday temporarily blocked all refugees while also denying  TL;DR   Silicon Valley Is Still Confident Trump’s Order Will Work<|endoftext|>\n",
      "While President Trump’s travel ban threw American airports into chaos last weekend, Bob Ferguson, the attorney general of Washington State, was biding his time on an airplane. On his way home from a conference of Democratic attorneys general in Florida, Mr. Ferguson landed a week ago in the center of a political and legal firestorm.   International Airport was in disarray, with protests massing. Gov. Jay Inslee, a fellow Democrat, had sent word to the at TL;DR   Trump’s Travel Ban Is a Big Deal<|endoftext|>\n",
      "MUMBAI, India  —   It was a bold and risky gamble by Prime Minister Narendra Modi of India that quickly seemed to backfire. The announcement of a ban on the largest currency bills circulating in India, which came into full effect at midnight Friday, the last day for depositing the old notes at banks, set off cash shortages that have hit the country’s most vulnerable people hard and prompted worries about the economy. But despite t TL;DR  “The New Delhi Deal’s Impact on India’s Economy<|endoftext|>\n",
      "Whether by train, ship or   trail, transit alternatives are poised to proliferate in 2017. Midyear, the Brightline express train in South Florida is expected to open, linking Miami and West Palm Beach. When it’s finished in 2019, travelers can make the trip between Miami and Orlando in three hours, while driving takes four. The terminus at the new downtown MiamiCentral station will include a food hall known as Central Fare. In Switzerland, the Gotthard Base Tunnel, TL;DR  TL;DR TL;DR TL;DR TL;DR TL;DR TL;DR TL;DR TL;DR TL;DR TL;DR TL;DR TL;DR TL;DR TL;DR TL;DR TL;DR TL;DR TL;DR TL;DR<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def summarize_article(article):\n",
    "    tokenized = tokenizer(article, return_tensors=\"np\")\n",
    "    outputs = model.generate(**tokenized, max_length=512)\n",
    "    return tokenizer.decode(outputs[0])\n",
    "\n",
    "max_input_len = MAX_LEN - len(TLDR)\n",
    "summaries = []\n",
    "with open('../data/test_data.txt', encoding='utf-8') as f:\n",
    "    for i in range(0, 10):\n",
    "        test_sentence = f.readline().split(TLDR)[0]\n",
    "        test_sentence = test_sentence[0:max_input_len] + TLDR\n",
    "        summaries.append(summarize_article(test_sentence))\n",
    "for summary in summaries:\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
